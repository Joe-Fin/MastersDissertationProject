import cv2
from PIL import Image
from random import randint 
import PIL
import random
import openslide as ops 
import math
import numpy as np
#from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.transforms.functional as F
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt 
from tiatoolbox.tools import patchextraction
import time
import os
import copy
import segmentation_models_pytorch as smp
from tqdm import tqdm

from tiatoolbox.wsicore.wsireader import WSIReader
from tiatoolbox.models.engine.semantic_segmentor import (
    IOSegmentorConfig,
    SemanticSegmentor,
)
from tiatoolbox.utils.misc import imread
UHCW_directory = 'random/'

UHCW_strings = list()
gpuid = 0


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
for image_string in os.listdir(UHCW_directory):
    UHCW_strings.append(os.path.join(UHCW_directory+image_string))

def get_padding(image):
    height = image.shape[0]
    width = image.shape[1]
    height_padding = height % 16
    width_padding = width % 16
    
    if (height_padding!=0):
      height_padding = 16 - height_padding 
    if (width_padding!=0):
      width_padding = 16 - width_padding 

    top_padding = math.ceil(height_padding/2)
    bottom_padding = math.floor(height_padding/2)

    right_padding =math.ceil(width_padding/2)


    left_padding = math.floor(width_padding/2)
    
    padding = (int(top_padding), int(bottom_padding), int(left_padding), int(right_padding))
    
    return padding



def sort_data(file_loc_data ,directory):
  test_X_data = list()
 
  # Sort validation data 
  for i in range(len(file_loc_data)):
    # We need to sort if the image is large or not
    io=cv2.cvtColor(cv2.imread(file_loc_data[i]),cv2.COLOR_BGR2RGB)
    count = 0 
    interp_method=PIL.Image.BICUBIC
    io = cv2.resize(io,(0,0),fx=1,fy=1, interpolation=interp_method) #resize it as specified above
  
    all_padding = get_padding(io)
    
    io = np.pad(io, pad_width=((all_padding[0], all_padding[1]), (all_padding[2], all_padding[3]),(0,0)))
    print(io.shape)

    
    test_X_data.append(io)

  return test_X_data



class UHCW_seg_test(Dataset):
  def __init__(self, transform=None):
    self.x = np.array(UHCW_images)
    self.n_samples =  self.x.shape[0]
    self.transform = transform

  def __getitem__(self,index):
    image = self.x[index]
    if self.transform is not None :
      image = self.transform(image)

    return image

  def __len__(self):
    return self.n_samples


transform_UHCW = transforms.Compose([
     #transforms.ToPILImage(),
     transforms.ToTensor()
    ])

def compose_masks (dataloader, model):
  progress = tqdm(dataloader)  
  model.eval()
  all_predictions = list()
  
  for batch_idx, (data) in enumerate(progress):
    
    data = data.type(torch.FloatTensor)
    X = data.to(device)
    
    with torch.set_grad_enabled(False):
       predictions = model(X)
       # Create 4d from prediction
       p=predictions[:,:,:,:].detach().cpu()
       cpred=np.argmax(p,axis=1)
       all_predictions.append(cpred)
    
  return all_predictions


def create_example(mask):
    mask_shape = mask.shape
    print(mask.shape)
    this_mask = np.zeros((mask_shape[0], mask_shape[1],3),dtype=np.uint8)
    for i in range(len(mask)):
      for j in range(len(mask[0])):
        if mask[i][j] == 0:
          this_mask[i][j] = [255,255,255]
        elif mask[i][j] == 1:
          this_mask[i][j] = [0,64,128]
        elif mask[i][j] == 2:
          this_mask[i][j] = [64,128,0]
        elif mask[i][j] == 3:
          this_mask[i][j] = [243,152,0]
    
    return Image.fromarray(this_mask)
  
def infer_batch(model, batch_data, on_gpu):
        """Run inference on an input batch.
        This contains logic for forward operation as well as
        i/o aggregation.
        Args:
            model (nn.Module): PyTorch defined model.
            batch_data (ndarray): A batch of data generated by
              torch.utils.data.DataLoader.
            on_gpu (bool): Whether to run inference on a GPU.
        Returns:
            List of network output head, each output is a `ndarray`.
        """
        model.eval()

        imgs = batch_data
        imgs = imgs.to("cuda").type(torch.float32)

        with torch.inference_mode():
            logits = model(imgs)
            logits = logits.permute(0, 2, 3, 1) # as your output is channels first so swap them

        logits = logits.detach().squeeze().cpu().numpy()
        return [logits]

img_transform = transforms.Compose([
     #transforms.ToPILImage(),
    
     transforms.ToTensor()
    ])
def preproc(image):
        """Define the pre-processing of this class of model."""
        # as before sending the patches we process them through the transforms
        # which will transform it and normalize it 
        return img_transform(image)


ON_GPU = True  # Should be changed to False if no cuda-enabled GPU is available

print(UHCW_strings)
UHCW_images = sort_data(UHCW_strings, UHCW_directory)
torch.cuda.empty_cache()
model = smp.DeepLabV3Plus(
    encoder_name="resnet50",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7
    encoder_weights=None,     # use `imagenet` pre-trained weights for encoder initialization
    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)
    classes=4,                      # model output channels (number of classes in your dataset)
).to(device)



model.load_state_dict(torch.load('/mnt/user-temp/joseph-tia/MSDissertation/deeplabplus_50_grid_second_after.pth')['model_state_dict'])
# adding the above function to our model as TIAToolbox will be looking for these
model.preproc_func = preproc
model.infer_batch = infer_batch
model.eval()



segmentation_UHCW = UHCW_seg_test(transform_UHCW)
dataloader_segmentation_UHCW = DataLoader(dataset = segmentation_UHCW, batch_size = 1, shuffle = False)

all_masks = compose_masks(dataloader_segmentation_UHCW, model)

for i in range(len(all_masks)):
  coloured_mask = create_example(all_masks[i].reshape(all_masks[i].shape[1],all_masks[i].shape[2]))
  coloured_mask.save('/mnt/user-temp/joseph-tia/MSDissertation/Deep_Lab_large/normal/'+str(i)+'.jpg', 'JPEG')



segmentation_UHCW = UHCW_seg_test(transform_UHCW)
dataloader_segmentation_UHCW = DataLoader(dataset = segmentation_UHCW, batch_size = 1, shuffle = False)



